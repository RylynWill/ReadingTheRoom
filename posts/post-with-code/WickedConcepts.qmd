---
title: "Wicked Concepts"
author: "Rylyn Williams"
format: 
  html: 
    df-print: paged
    embed-resources: true
    code-fold: true
    self-contained-math: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
```

```{r include=FALSE}
library(tidyverse)
library(haven)
library(readr)
library(readxl)
library(tnet)
library(igraph)
library(statnet)
library(concoR)
library(GGally)
library(centiserve)
options(scipen=999)
```

```{r include=FALSE}
get.eigen<-function(net){
    eigen <- sna::evcent(net)
    adj_matrix <- as.matrix.network(net, attr="w")  # Use weights as edge strengths
    diag(adj_matrix) <- 0  # Set diagonal elements to 0
    degree_strength <- rowSums(adj_matrix)  # Calculate degree strength
    adj_matrix <- adj_matrix / degree_strength  # Normalize by degree strength
    mat2 <- adj_matrix %*% adj_matrix
    rc <- diag(mat2) / rowSums(mat2)
    dc <- 1 - rc
    data.frame(name = net %v% "vertex.names",
               eigen = eigen,
               eigen.rc = eigen * rc,
               eigen.dc = eigen * dc)
}
```

```{r include=FALSE}
#plotting block model
plot.block<-function(x=blk_mod, main=NULL, cex.lab=1){
  plot.sociomatrix(x$blocked.data, labels=list(x$plabels,x$plabels),
                   main=main, drawlines = FALSE, cex.lab=cex.lab)
  for (j in 2:length(x$plabels)) if (x$block.membership[j] !=
                                     x$block.membership[j-1]) 
    abline(v = j - 0.5, h = j - 0.5, lty = 3, xpd=FALSE)
}
```

## Data wrangling

```{r include =FALSE}
#read in data tables from survey, 35 by 9 data table
q1 <- read_csv("data/q1.csv", show_col_types = FALSE)
q2 <- read_csv("data/q2.csv", show_col_types = FALSE)
q3 <- read_csv("data/q3.csv", show_col_types = FALSE)
q4 <- read_csv("data/q4.csv", show_col_types = FALSE)
q5 <- read_csv("data/q5.csv", show_col_types = FALSE )
# remove total row so that it's 35 by 8, including column of concepts
q1 <- select(q1, -9)
q2 <- select(q2, -9)
q3 <- select(q3, -9)
q4 <- select(q4, -9)
q5 <- select(q5, -9)
```

```{r}
head(q1, 2)
head(q2, 2)
head(q3, 2)
head(q4, 2)
head(q5, 2)
```

```{r}
# Join columns by term column, to create 35 by 35
concepts <- left_join(q1,q2,by="...1")
concepts <- left_join(concepts,q3,by="...1")
concepts <- left_join(concepts,q4,by="...1")
concepts <- left_join(concepts,q5,by="...1")
concepts <- select(concepts, -1)
rownames(concepts)<-colnames(concepts)
names.attr <- tibble(id = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35), name = colnames(concepts))

```

\`

```{r}
concepts <- as.matrix(concepts)
#replace NA's with Zero as the value is not missing, there is just no tie so there weight it 0
concepts[is.na(concepts)] <- 0
# Set diag to false to remove self loops
cg <- graph_from_adjacency_matrix(concepts)
#Save the graph as a data frame that shows each ties and their weight.
cg_frame <-get.data.frame(cg)
```

### Create a tnet object out of single counted actor ties, with weights being the count of the tie appearence

```{r}
# Identify unique vertices
unique_vertices <- unique(c(cg_frame$from, cg_frame$to))
valid_vertices <- unique_vertices[nchar(unique_vertices) > 0]

# Create an empty graph
cg_graph <- graph(edges = numeric(0), directed = FALSE)

# Add vertices to the graph
cg_graph <- add_vertices(cg_graph, nv = length(valid_vertices), name = valid_vertices)

# Count tie occurrences, the number of times that tie occurs, will be it's strength/weight
ties_count <- table(apply(cg_frame, 1, function(x) paste(sort(x), collapse = "-")))

# Adjust tie counts for subsequent ties # this will count reverse ties so B to A where the code above check A to B
unique_ties <- unique(apply(cg_frame, 1, function(x) paste(sort(x), collapse = "-")))

for (tie in unique_ties) {
  ties_count[tie] <- ifelse(ties_count[tie] > 1, ties_count[tie], ties_count[tie] + 1)
}

# Process ties data
tie_parts <- strsplit(names(ties_count), "-")
from_vertices <- sapply(tie_parts, `[`, 1)
to_vertices <- sapply(tie_parts, `[`, 2)
weights <- as.vector(ties_count)

# Create a data frame
cg_tie_df <- data.frame(from = from_vertices, to = to_vertices, weight = weights)

# Print the data frame
head(cg_tie_df)
```

### creating tnet and statnet object

```{r}
## Tnet objects only except integers, so have to set from/to columns to integers
cg_tie_df$from <- as.integer(as.factor(cg_tie_df$from))
cg_tie_df$to <- as.integer(as.factor(cg_tie_df$to))


#create networks
cg_tnet <- as.tnet(cg_tie_df, type = "weighted one-mode tnet")
cg.ig <- tnet_igraph(cg_tnet, type = "weighted one-mode tnet", directed = NULL)
cg.stat <- as.network.matrix(cg_tnet)

# Assign node names as vertex attributes to cg.ig & cg.stat network
V(cg.ig)$name <-  names.attr$name
network.vertex.names(cg.stat) <- names.attr$name

```

## Node-Level Measures

```{r}

#get betweenness, power centrality, degree strength (based on weights), closeness, and constraints
cg.nodes<-data.frame(name=cg.stat%v%"vertex.names",
        degree.wt=igraph::strength(cg.ig),
        power.cent =igraph::power_centrality(cg.ig),
        betweenness=sna::betweenness(cg.stat, gmode="graph"),
        close=sna::closeness(cg.stat, gmode="graph"),
        constraint=igraph::constraint(cg.ig))
eigen_cent_df <- as.data.frame(eigen_centrality(cg.ig))
eigen_cent_df <- head(eigen_cent_df,35)
cg.nodes<-cbind(cg.nodes, eigen_cent_df)
cg.nodes <- head(cg.nodes,35) # don't care about place holder empty columns,
cg.nodes <- cg.nodes[, 1:8]
head(cg.nodes, 9)
```

## Structural Equivalence

```{r}
#STRUCTUAL Equivalence 
cg.se <-equiv.clust(cg.stat,
                          equiv.fun = "sedist",
                          method = "hamming", 
                          mode = "graph")
plot(cg.se,labels = cg.se$glabels)
#Average Cluster Method
cg.ase <- equiv.clust(cg.stat,
                          equiv.fun = "sedist",
                      cluster.method = "average",
                          method = "hamming", 
                          mode = "graph")
plot(cg.ase, cg.ase$glabels)

#Single Cluster Method
cg.sse<- equiv.clust(cg.stat,
                          equiv.fun = "sedist",
                      cluster.method = "single",
                          method = "hamming", 
                          mode = "graph")
plot(cg.sse,labels = cg.sse$glabels)

# Ward.D method
cg.wse<- equiv.clust(cg.stat,
                          equiv.fun = "sedist",
                      cluster.method = "ward.D",
                          method = "hamming", 
                          mode = "graph")
plot(cg.wse,labels = cg.wse$glabels)

```

## Partitioning

### Height equal to 5

```{r}
#Partitioning regular clustering -5
plot(cg.se,labels = cg.se$glabels)
rect.hclust(cg.se$cluster, h = 5)

#Partitioning Average Cluster Method -5
plot(cg.ase,labels = cg.ase$glabels)
rect.hclust(cg.ase$cluster, h = 5)

#Partitioning Single Cluster Method -5
plot(cg.sse,labels = cg.sse$glabels)
rect.hclust(cg.sse$cluster, h = 5)

#Partitioning Ward.D method -5
plot(cg.wse,labels = cg.wse$glabels)
rect.hclust(cg.se$cluster, h = 5)
cg.nodes<-full_join(cg.nodes, get.eigen(cg.stat), by="name")
```

## BlockModeling

```{r}
#testing block model
block_wse <-blockmodel(cg.stat, cg.ase, k=9, h=5) #tryin out 5
#View model
plot.block(block_wse, cex.lab=.5)
```

## Let's Plot this

### Statnet

```{r}
# chosen blockmodel and chose partition partitions
cg_mod <- blockmodel(cg.stat, cg.ase, k=9)
# assign block membership to vertex attribute
cg.stat%v%"role" <- cg_mod$block.membership[match(cg.stat%v%"vertex.names",
                                                     cg_mod$plabels)]

GGally::ggnet2(cg.stat,
               node.color = "role",
               node.size = degree(cg.stat, gmode = "graph"),
               node.label = "vertex.names",
               node.alpha = .7)
```

### igraph

```{r}
V(cg.ig)$role <- cg_mod$block.membership[match(V(cg.ig)$name, cg_mod$plabels)]
plot.igraph(cg.ig,
            vertex.color = V(cg.ig)$role,
            vertex.size = 0.5+(igraph::degree(cg.ig)*0.5))
```
